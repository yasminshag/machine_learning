{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading CSV file using pandas \n",
    "df = pd.read_csv('agr_en_train.csv', names = ['unique_id','comment','agr_lvl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_id                          facebook_corpus_msr_1723796\n",
      "comment      Well said sonu..you have courage to stand agai...\n",
      "agr_lvl                                                    OAG\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#We can see how the first example looks like below\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store the reviews and labels in two arrays as follows:\n",
    "reviews = df['comment'].values\n",
    "labels_str = df['agr_lvl'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the reviews\n",
    "print(reviews,len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "['OAG' 'NAG' 'OAG' ... 'OAG' 'OAG' 'NAG']\n"
     ]
    }
   ],
   "source": [
    "#we convert the labels from array of string to array of integers for computation i.e. labels \n",
    "label2value_dic={'OAG':2,'CAG':1,'NAG':0}\n",
    "\n",
    "labels=np.zeros(len(labels_str),dtype=int)\n",
    "for tt,tkey in enumerate(label2value_dic.keys()):\n",
    "    ind_this=labels_str==tkey\n",
    "    labels[ind_this]=label2value_dic[tkey]\n",
    "    #print(tt,tkey)\n",
    "    \n",
    "print(np.unique(labels))\n",
    "print(labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the split size and splitting the index in k folds\n",
    "#should be executed only once as it shuffles the data in random order in every execution \n",
    "class kfoldValidation:\n",
    "    def __init__(self, datasize,k):\n",
    "        self.k = k\n",
    "        self.foldsize=np.int(np.floor(datasize*1.0/k))\n",
    "        self.index_arr=np.arange(datasize)\n",
    "        np.random.shuffle(self.index_arr)\n",
    "        \n",
    "    def getfold(self,x):\n",
    "        if(self.k-1==x):\n",
    "            index_test=self.index_arr[x*self.foldsize:]\n",
    "            index_train=self.index_arr[:x*self.foldsize]\n",
    "        else:\n",
    "            index_test=self.index_arr[x*self.foldsize:((x+1)*self.foldsize)]\n",
    "            index_train=np.append(self.index_arr[:x*self.foldsize],self.index_arr[(x+1)*self.foldsize:])\n",
    "\n",
    "        return index_test, index_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on fold (with kernel= linear):0/10\n",
      "working on fold (with kernel= linear):1/10\n",
      "working on fold (with kernel= linear):2/10\n",
      "working on fold (with kernel= linear):3/10\n",
      "working on fold (with kernel= linear):4/10\n",
      "working on fold (with kernel= linear):5/10\n",
      "working on fold (with kernel= linear):6/10\n",
      "working on fold (with kernel= linear):7/10\n",
      "working on fold (with kernel= linear):8/10\n",
      "working on fold (with kernel= linear):9/10\n",
      "kernel used:  linear\n",
      "mean overall accuracy = 0.5617100895337727\n",
      "mean precision=  0.5562720770943074 mean precision per class [0.63482497 0.4806589  0.55333236]\n",
      "mean recall   =  0.5282042904024576 mean recall per class [0.69268917 0.53987579 0.3520479 ]\n",
      "mean f1       =  0.53334816300879 mean f1 per class [0.66218878 0.50806753 0.42978818]\n",
      "working on fold (with kernel= poly):0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasmin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\yasmin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on fold (with kernel= poly):1/10\n",
      "working on fold (with kernel= poly):2/10\n",
      "working on fold (with kernel= poly):3/10\n",
      "working on fold (with kernel= poly):4/10\n",
      "working on fold (with kernel= poly):5/10\n",
      "working on fold (with kernel= poly):6/10\n",
      "working on fold (with kernel= poly):7/10\n",
      "working on fold (with kernel= poly):8/10\n",
      "working on fold (with kernel= poly):9/10\n",
      "kernel used:  poly\n",
      "mean overall accuracy = 0.4209501985650294\n",
      "mean precision=  0.14031673285500978 mean precision per class [0.4209502 0.        0.       ]\n",
      "mean recall   =  0.3333333333333333 mean recall per class [1. 0. 0.]\n",
      "mean f1       =  0.19740499010596624 mean f1 per class [0.59221497 0.         0.        ]\n",
      "working on fold (with kernel= sigmoid):0/10\n",
      "working on fold (with kernel= sigmoid):1/10\n",
      "working on fold (with kernel= sigmoid):2/10\n",
      "working on fold (with kernel= sigmoid):3/10\n",
      "working on fold (with kernel= sigmoid):4/10\n",
      "working on fold (with kernel= sigmoid):5/10\n",
      "working on fold (with kernel= sigmoid):6/10\n",
      "working on fold (with kernel= sigmoid):7/10\n",
      "working on fold (with kernel= sigmoid):8/10\n",
      "working on fold (with kernel= sigmoid):9/10\n",
      "kernel used:  sigmoid\n",
      "mean overall accuracy = 0.42095579097371427\n",
      "mean precision=  0.14031859699123808 mean precision per class [0.42095579 0.         0.        ]\n",
      "mean recall   =  0.3333333333333333 mean recall per class [1. 0. 0.]\n",
      "mean f1       =  0.1974442948513759 mean f1 per class [0.59233288 0.         0.        ]\n",
      "working on fold (with kernel= rbf):0/10\n",
      "working on fold (with kernel= rbf):1/10\n",
      "working on fold (with kernel= rbf):2/10\n",
      "working on fold (with kernel= rbf):3/10\n",
      "working on fold (with kernel= rbf):4/10\n",
      "working on fold (with kernel= rbf):5/10\n",
      "working on fold (with kernel= rbf):6/10\n",
      "working on fold (with kernel= rbf):7/10\n",
      "working on fold (with kernel= rbf):8/10\n",
      "working on fold (with kernel= rbf):9/10\n",
      "kernel used:  rbf\n",
      "mean overall accuracy = 0.42095392683748595\n",
      "mean precision=  0.14031797561249532 mean precision per class [0.42095393 0.         0.        ]\n",
      "mean recall   =  0.3333333333333333 mean recall per class [1. 0. 0.]\n",
      "mean f1       =  0.19745137685516634 mean f1 per class [0.59235413 0.         0.        ]\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#this class is performing the training and validation on data\n",
    "\n",
    "def perform_kfold_validation(kernel='linear',k=10):\n",
    "    \n",
    "    #kfoldValidation needs to be executed only once as it shuffles the data in every execution and updates the index\n",
    "    kfold = kfoldValidation(len(reviews),k)\n",
    "\n",
    "    for ii in range(k):\n",
    "        \n",
    "        print('working on fold (with kernel= %s):%d/%d'%(kernel,ii,k))\n",
    "        \n",
    "        #to get the test and training data index in each fold\n",
    "        test_index,train_index=kfold.getfold(ii)\n",
    "\n",
    "\n",
    "        #Feature Extraction/Vectorisation\n",
    "        #it reduces the impact of tokens used very frequently\n",
    "        vectorizer = TfidfVectorizer(min_df=5,sublinear_tf=True)\n",
    "\n",
    "        #training the model on train data for each fold\n",
    "        train_vectors = vectorizer.fit_transform(reviews[train_index])\n",
    "        test_vectors = vectorizer.transform(reviews[test_index])\n",
    "\n",
    "        #SVM RBF/Gaussian Kernel (default)\n",
    "        classifier = svm.SVC(kernel=kernel)\n",
    "        classifier.fit(train_vectors, labels[train_index]) #train classifier on train data\n",
    "        prediction = classifier.predict(test_vectors) #predict test data\n",
    "\n",
    "        #get classification results/evaluate model\n",
    "        report = metrics.precision_recall_fscore_support(labels[test_index], prediction)\n",
    "        report_accuracy = accuracy_score(labels[test_index], prediction)\n",
    "\n",
    "        if(ii==0):\n",
    "            precision=report[0]\n",
    "            recall=report[1]\n",
    "            f1=report[2]\n",
    "            accuracy=np.array([report_accuracy])\n",
    "        else:\n",
    "            precision=np.row_stack([precision,report[0]])\n",
    "            recall=np.row_stack([recall,report[1]])\n",
    "            f1=np.row_stack([f1,report[2]])\n",
    "            accuracy=np.append(accuracy,report_accuracy)     \n",
    "           \n",
    "    return precision, recall,f1,accuracy\n",
    "\n",
    "#calling the above function and taking the value of k as 10\n",
    "k=10\n",
    "for kernel in ['linear','poly','sigmoid','rbf']:\n",
    "    precision, recall,f1,accuracy=perform_kfold_validation(kernel=kernel,k=k)\n",
    "    \n",
    "    print('kernel used: ',kernel)\n",
    "    print('mean overall accuracy =',np.mean(accuracy))\n",
    "    print('mean precision= ',np.mean(precision),'mean precision per class',np.mean(precision,axis=0))\n",
    "    print('mean recall   = ',np.mean(recall),'mean recall per class',np.mean(recall,axis=0))\n",
    "    print('mean f1       = ',np.mean(f1),'mean f1 per class',np.mean(f1,axis=0))\n",
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
